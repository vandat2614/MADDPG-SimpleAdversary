{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from maddpg import MADDPG\n",
    "from buffer import MultiAgentReplayBuffer\n",
    "from pettingzoo.mpe import simple_adversary_v3\n",
    "import warnings\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = 'simple_adversary'\n",
    "env = simple_adversary_v3.parallel_env(continuous_actions=True,render_mode='human')\n",
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, ['adversary_0', 'agent_0', 'agent_1'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.num_agents, env.agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_agents = env.num_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adversary_0 - Box(-inf, inf, (8,), float32) - (8,)\n",
      "agent_0 - Box(-inf, inf, (10,), float32) - (10,)\n",
      "agent_1 - Box(-inf, inf, (10,), float32) - (10,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pettingzoo\\utils\\conversions.py:144: UserWarning: The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8, 10, 10]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_dims = []\n",
    "for agent_name in env.agents:\n",
    "    print(f'{agent_name} - {env.observation_spaces[agent_name]} - {env.observation_spaces[agent_name].shape}')\n",
    "    actor_dims.append(env.observation_spaces[agent_name].shape[0])\n",
    "actor_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critic_dims = sum(actor_dims)\n",
    "critic_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adversary_0 - Box(0.0, 1.0, (5,), float32) - (5,)\n",
      "agent_0 - Box(0.0, 1.0, (5,), float32) - (5,)\n",
      "agent_1 - Box(0.0, 1.0, (5,), float32) - (5,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pettingzoo\\utils\\conversions.py:158: UserWarning: The `action_spaces` dictionary is deprecated. Use the `action_space` function instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for agent_name in env.agents:\n",
    "    print(f'{agent_name} - {env.action_spaces[agent_name]} - {env.action_spaces[agent_name].shape}')\n",
    "# all agent has 5 action\n",
    "n_actions = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adversary_0': array([-1.2346485 ,  1.4577886 , -0.5728462 ,  1.1731899 ,  0.22436805,\n",
       "        -0.01101489, -0.54150075,  0.96164197], dtype=float32),\n",
       " 'agent_0': array([-1.4590166 ,  1.4688034 , -1.4590166 ,  1.4688034 , -0.79721427,\n",
       "         1.1842048 , -0.22436805,  0.01101489, -0.7658688 ,  0.97265685],\n",
       "       dtype=float32),\n",
       " 'agent_1': array([-0.6931477 ,  0.4961466 , -0.6931477 ,  0.4961466 , -0.03134545,\n",
       "         0.21154793,  0.54150075, -0.96164197,  0.7658688 , -0.97265685],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\spaces\\box.py:240: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "  gym.logger.warn(\"Casting input x to numpy array.\")\n"
     ]
    }
   ],
   "source": [
    "actions = {\n",
    "    'adversary_0' : [0.2, 0.3, 0.5, 0, 0],\n",
    "    'agent_0' : [0.5, 0, 0, 0, 0.5],\n",
    "    'agent_1' : [1, 0, 0, 0, 0],\n",
    "}\n",
    "\n",
    "next_state, reward, termination, truncation, info = env.step(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adversary_0': array([-0.08454347, -0.06841106,  1.4396316 ,  1.3236113 ,  0.19912532,\n",
       "         0.99912477,  1.4778169 ,  0.6007171 ], dtype=float32),\n",
       " 'agent_0': array([ 1.2405063 ,  0.32448646, -0.2836688 , -1.0675359 ,  1.2405063 ,\n",
       "         0.32448646, -0.19912532, -0.99912477,  1.2786916 , -0.39840764],\n",
       "       dtype=float32),\n",
       " 'agent_1': array([-0.03818534,  0.7228941 , -1.5623604 , -0.6691282 , -0.03818534,\n",
       "         0.7228941 , -1.4778169 , -0.6007171 , -1.2786916 ,  0.39840764],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'adversary_0': -1.9556292612005246,\n",
       "             'agent_0': 1.2317273332334362,\n",
       "             'agent_1': 1.2317273332334362})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adversary_0': False, 'agent_0': False, 'agent_1': False}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "termination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adversary_0': False, 'agent_0': False, 'agent_1': False}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adversary_0': {}, 'agent_0': {}, 'agent_1': {}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.08454347, -0.06841106,  1.4396316 ,  1.3236113 ,  0.19912532,\n",
       "         0.99912477,  1.4778169 ,  0.6007171 ,  1.2405063 ,  0.32448646,\n",
       "        -0.2836688 , -1.0675359 ,  1.2405063 ,  0.32448646, -0.19912532,\n",
       "        -0.99912477,  1.2786916 , -0.39840764, -0.03818534,  0.7228941 ,\n",
       "        -1.5623604 , -0.6691282 , -0.03818534,  0.7228941 , -1.4778169 ,\n",
       "        -0.6007171 , -1.2786916 ,  0.39840764], dtype=float32),\n",
       " (28,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.concatenate([i for i in next_state.values()])\n",
    "t, t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adversary_0', 'agent_0', 'agent_1']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.possible_agents # return list alive agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MultiAgentReplayBuffer(1000000, critic_dims, actor_dims,\n",
    "                                n_actions, n_agents, batch_size=1024,\n",
    "                                agent_names=env.agents)\n",
    "# critic_dims = 28\n",
    "# actor_dims = [8, 10, 10]\n",
    "# n_actions = 5\n",
    "# n_agents = 3\n",
    "# agents_names = ['adversary_0', 'agent_0', 'agent_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory.store_transition(obs, state, actions, reward, obs_, state_, done)\n",
    "\n",
    "# obs : list, keys = agent_names, values = agent_states\n",
    "# state : np.array with shape = (28, ) = 8 + 10 + 10\n",
    "# actions: list, keys = agent_names, values = probs action for each agent [0.5, 0.5, 0, 0, 0]\n",
    "# reward: list, keys = agent_names, values = number for each agent\n",
    "# obs_ same obs\n",
    "# state_ same state\n",
    "# done = [True, False, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sample_buffer(self):\n",
    "\n",
    "# actor_states: list with len = n_agents, each elemt with shape = (batch, state_len = 8 or 10)\n",
    "# states: np array shape (batch, 28)\n",
    "# actions: same actor_states, each has shape = (batch, 5), overall (3, batch, 5)\n",
    "# rewards: np array shape (batch, 3) <- 3 agent\n",
    "# actor_new_states: same actor_states\n",
    "# states_: same states\n",
    "# terminal: saem rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = sum(reward) each action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maddpg_agents = MADDPG(actor_dims, critic_dims, n_agents, n_actions, #!\n",
    "#                         fc1=64, fc2=64,\n",
    "#                         alpha=0.01, beta=0.01, scenario=scenario,\n",
    "#                         chkpt_dir='tmp/maddpg/')\n",
    "\n",
    "# actor_dims: list = [8, 10, 10]\n",
    "# critic_dims: scalar = 28\n",
    "# n_agents: scalar = 3\n",
    "# n_actions: scalar = 5\n",
    "# alpha: lr for adam optimizer of Actor\n",
    "# beta: lr fo adam optimizer of Critic\n",
    "# scenario: string = 'simple_adversary'\n",
    "# chkpt_dir: checkpoint folder \n",
    "    # - in constructor: checkpoint folder = chkpt_dir + scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Agent:\n",
    "#     def __init__(self, actor_dims, critic_dims, n_actions, n_agents,  chkpt_dir,agent_name,\n",
    "#                     alpha=0.01, beta=0.01, fc1=64,\n",
    "#                     fc2=64, gamma=0.95, tau=0.01 ,\n",
    "#                     ):\n",
    "\n",
    "# agent_name: string, ex: 'adversary_0'\n",
    "# alpha: for optimiz actor    \n",
    "# beta: for optimize critic\n",
    "# gamma:\n",
    "# tau: % main network use for update target\n",
    "# chkpt_dir =  chkpt_dir + scenario "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CriticNetwork(nn.Module):\n",
    "#     def __init__(self, beta, input_dims, fc1_dims, fc2_dims, \n",
    "#                     n_agents, n_actions, name, chkpt_dir):\n",
    "\n",
    "# n_agents: scalar = 3\n",
    "# n_actions: scalar = 5\n",
    "# input_dims: critics_dims = 28\n",
    "# name: string = agent_name + critic, ex: 'agent_0_critic'\n",
    "# beta: optimize critic network\n",
    "# chkpt_dir =  chkpt_dir + scenario, same in Agent\n",
    "    # in constructor: chkpt_file = chk_pt + name\n",
    "\n",
    "# neural net with input = 28 + 5 * 3, output is scalar for evaluate\n",
    "\n",
    "# def forward(self, state, action):\n",
    "# state: (batch, 28), (batch, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ActorNetwork(nn.Module):\n",
    "#     def __init__(self, alpha, input_dims, fc1_dims, fc2_dims, \n",
    "#                  n_actions, name, chkpt_dir):\n",
    "#         super(ActorNetwork, self).__init__()\n",
    "\n",
    "# alpha: for optimize network\n",
    "# input_dims: scalar one of [8, 10, 10]\n",
    "# n_actions: scalar = 5\n",
    "# name: string =agent_name + actor, ex: 'agent_1_actor' or 'agent_1_target_actor' for target\n",
    "# chkpt_dir =  chkpt_dir + scenario, same in Agent\n",
    "    # in constructor: chkpt_file = chk_pt + name\n",
    "\n",
    "# def forward(self, state):\n",
    "# state: torch tensor (batch, dims tương ứng với agent 8 hoặc 10)\n",
    "# pi: ma trận xác suất [batch, dài 5, mỗi hàng là 1 phân phối xác suất]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.2629526 ,  0.66632277, -0.17945327,  1.1819197 ,  0.03000507,\n",
       "        0.52336186, -0.00786891,  0.7526242 ], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_obs = env.reset()[0]\n",
    "\n",
    "input_for_agent = raw_obs['adversary_0'] # array np\n",
    "input_for_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14084\\1662024860.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  T.Tensor([input_for_agent])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2630,  0.6663, -0.1795,  1.1819,  0.0300,  0.5234, -0.0079,  0.7526]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.Tensor([input_for_agent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2630,  0.6663, -0.1795,  1.1819,  0.0300,  0.5234, -0.0079,  0.7526]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = T.Tensor([input_for_agent]).detach()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.2630,  0.3337,  1.1795, -0.1819,  0.9700,  0.4766,  1.0079,  0.2474]])\n",
      "tensor(-0.1819)\n"
     ]
    }
   ],
   "source": [
    "print(1-a)\n",
    "print((1-a).min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2630,  0.6663, -0.1795,  1.1819,  0.0300,  0.5234, -0.0079,  0.7526]])\n",
      "[[-1.2629526   0.66632277 -0.17945327  1.1819197   0.03000507  0.52336186\n",
      "  -0.00786891  0.7526242 ]]\n"
     ]
    }
   ],
   "source": [
    "# output trong 1 agent sau khi choose action tương tự như trên\n",
    "print(T.Tensor([input_for_agent]).detach())\n",
    "print(T.Tensor([input_for_agent]).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 2, 3], [0, 0, -1]])\n",
    "T.tensor(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 5])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[1, 1, 1, 1, 1], [2, 2, 2, 2, 2], [3, 3, 3, 3, 3]]\n",
    "T.tensor([a, a, a, a]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2],\n",
       "         [3, 4]]),\n",
       " tensor([[5, 6],\n",
       "         [7, 8]]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = T.tensor([[1, 2], [3, 4]])\n",
    "b = T.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6],\n",
       "        [7, 8]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.cat([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6],\n",
       "        [7, 8]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.cat([a, b], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 5, 6],\n",
       "        [3, 4, 7, 8]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.cat([a, b], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 5, 6],\n",
       "        [3, 4, 7, 8]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.cat([a, b], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1],\n",
       "         [2],\n",
       "         [3]]),\n",
       " torch.Size([3, 1]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = T.tensor([[1], [2], [3]])\n",
    "a, a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[False],\n",
       "         [ True],\n",
       "         [False]]),\n",
       " torch.Size([3, 1]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = T.tensor([[False], [True], [False]])\n",
    "b, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [0],\n",
       "        [3]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[b[:,0]]=0\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=T.tensor([[1], [2], [3]]).flatten()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 3])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "a[b[:,0]]=0\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
